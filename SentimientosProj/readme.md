# üìù An√°lisis de Sentimientos con Machine Learning

![Machine Learning](https://img.shields.io/badge/Machine-Learning-orange) ![Python](https://img.shields.io/badge/Python-3.10-blue) ![Status](https://img.shields.io/badge/Status-Active-success) ![License](https://img.shields.io/badge/License-MIT-lightgrey)

Este proyecto se centra en la **clasificaci√≥n de opiniones positivas y negativas** utilizando t√©cnicas de **aprendizaje supervisado**. Se implementaron y compararon modelos de **Naive Bayes** y **Regresi√≥n Log√≠stica** para evaluar su desempe√±o en un conjunto de rese√±as desbalanceado.

---

## üéØ Objetivo

El objetivo principal es:

> **Desarrollar un modelo de Machine Learning capaz de analizar autom√°ticamente opiniones de usuarios y clasificarlas en positivas o negativas, con √©nfasis en el tratamiento de datos desbalanceados para mejorar la detecci√≥n de rese√±as negativas.**

---

## üîé Enfoque Metodol√≥gico

El proyecto sigue un flujo de trabajo t√≠pico en **Procesamiento de Lenguaje Natural (NLP)** y **Ciencia de Datos**:

1. **An√°lisis Exploratorio de Datos (EDA):**

   * Distribuci√≥n de opiniones positivas y negativas.
   * Identificaci√≥n de desbalance de clases.
   * Limpieza y preprocesamiento del texto (tokenizaci√≥n, stopwords, lematizaci√≥n).

2. **Representaci√≥n del Texto:**

   * Vectorizaci√≥n con **Bag of Words** y **TF-IDF**.

3. **Modelado Predictivo:**

   * Entrenamiento de **Naive Bayes** y **Regresi√≥n Log√≠stica**.
   * Evaluaci√≥n en un dataset con alta desproporci√≥n de clases.

4. **Evaluaci√≥n del Modelo:**

   * M√©tricas utilizadas: **Accuracy**, **Precision**, **Recall**, **F1-score**.
   * Comparaci√≥n de desempe√±o entre modelos.

5. **Optimizaci√≥n y Consideraciones:**

   * An√°lisis del impacto del **desbalance de clases**.
   * Discusi√≥n de t√©cnicas futuras (re-sampling, ajuste de umbral, embeddings).

---

## üìå Hallazgos Clave

* Ambos modelos obtienen **alto rendimiento en la detecci√≥n de opiniones positivas** (f1 > 0.95).
* El desempe√±o en la **detecci√≥n de opiniones negativas** es bajo (recall = 0.25), lo que confirma la dificultad del desbalance.
* La **Regresi√≥n Log√≠stica supera levemente a Naive Bayes** en precisi√≥n y m√©tricas globales.

---

## üìà Resultados del Modelo

| Modelo             | Accuracy | F1 (Positivo) | F1 (Negativo) | Macro F1 |
| ------------------ | -------- | ------------- | ------------- | -------- |
| **Naive Bayes**    | 0.91     | 0.95          | 0.34          | 0.65     |
| **Reg. Log√≠stica** | 0.92     | 0.96          | 0.36          | 0.66     |

> ‚úÖ La Regresi√≥n Log√≠stica ofrece un desempe√±o ligeramente superior, aunque ambos modelos presentan limitaciones para detectar sentimientos negativos.

---

## üèÅ Conclusi√≥n e Implicaciones

El an√°lisis confirma que los modelos de **Machine Learning tradicionales** funcionan bien para clasificar rese√±as positivas, pero **presentan limitaciones frente al desbalance de clases** al analizar rese√±as negativas.

* **Regresi√≥n Log√≠stica** es la opci√≥n m√°s s√≥lida en este escenario, aunque la diferencia frente a Naive Bayes es m√≠nima.
* Para una aplicaci√≥n m√°s robusta, se recomienda:

  * Rebalanceo de clases (SMOTE, oversampling).
  * Ajuste de umbrales de decisi√≥n.
  * Uso de **embeddings modernos (BERT, Word2Vec, FastText)** para capturar mejor los matices del lenguaje.

En conjunto, este proyecto sienta las bases para la **automatizaci√≥n del an√°lisis de opiniones de usuarios**, con aplicaciones en atenci√≥n al cliente, marketing digital y monitoreo de la reputaci√≥n de marca.

---

üìÇ Parte del repositorio: *Proyectos de Machine Learning aplicados a Procesamiento de Lenguaje Natural (NLP).*

